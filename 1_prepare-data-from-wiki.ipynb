{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bs4\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder structure\n",
    "fp = os.path.join('.', 'data', '1_wiki-raw')\n",
    "if not os.path.isdir(fp):\n",
    "    os.makedirs(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of cities and wiki urls\n",
    "city_urls = {\n",
    "    'new_york': 'https://en.wikipedia.org/wiki/List_of_Michelin_starred_restaurants_in_New_York_City',\n",
    "    'chicago': 'https://en.wikipedia.org/wiki/List_of_Michelin_starred_restaurants_in_Chicago',\n",
    "    'san_francisco': 'https://en.wikipedia.org/wiki/List_of_Michelin_starred_restaurants_in_San_Francisco_Bay_Area',\n",
    "    'washington_dc': 'https://en.wikipedia.org/wiki/List_of_Michelin_starred_restaurants_in_Washington,_D.C.',\n",
    "#     'los_angeles': 'https://en.wikipedia.org/wiki/List_of_Michelin_starred_restaurants_in_Los_Angeles',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save lists of US Michelin-starred restaurants to disk\n",
    "for city_name in city_urls:\n",
    "    url = city_urls[city_name]\n",
    "    html = urlopen(url)\n",
    "    page_content = html.read()\n",
    "    export_fp = os.path.join(fp, city_name + '_page_content.html')\n",
    "    with open(export_fp, 'wb') as fid:\n",
    "         fid.write(page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_table_to_df(table, city_name):\n",
    "    '''\n",
    "    Takes a Wikipedia HTML table of a city's Michelin starred restaurants by year \n",
    "    and converts the table to a dataframe, with a city_name column denoting\n",
    "    the name of the city\n",
    "    '''\n",
    "    col_list = ['city_name']\n",
    "    year_regex = re.compile(r'^\\d{4}') # matches first 4 digits for text that starts with 4 digits\n",
    "\n",
    "    # get list of column names and years from table\n",
    "    for col_header in table.find_all('th'):\n",
    "        header_text = col_header.text.strip('\\n')\n",
    "        mo = year_regex.search(header_text)\n",
    "        if mo is None:\n",
    "            col_list.append(header_text)\n",
    "        else:\n",
    "            col_list.append(mo.group())\n",
    "    \n",
    "    # get list of years (only applicable for Washington DC)\n",
    "    for cell in table.find_all('td'):\n",
    "        cell_text = cell.text\n",
    "        mo = year_regex.search(cell_text)\n",
    "        if mo is None:\n",
    "            pass\n",
    "        else:\n",
    "            col_list.append(mo.group())\n",
    "    \n",
    "    # get number of rows\n",
    "    row_num = len([row for row in table.find_all('tr')])\n",
    "    \n",
    "    # create a DataFrame to store info\n",
    "    df = pd.DataFrame(columns=col_list, index=range(0, row_num-1)) \n",
    "\n",
    "    # get the text and star rating for each cell\n",
    "    row_counter = 0\n",
    "    for row in table.find_all('tr')[1:]:\n",
    "        column_counter = 1\n",
    "        columns = row.find_all('td')\n",
    "        for column in columns:\n",
    "            if column.get('colspan'):\n",
    "                width = int(column.get('colspan'))\n",
    "                for i in range(0,width):\n",
    "                    df.iat[row_counter,column_counter] = 'Closed'\n",
    "                    column_counter+=1\n",
    "            else:\n",
    "                stars = [img['alt'] for img in column.find_all('img')] # star rating is captured in alt text\n",
    "                cell_text = column.get_text().strip('\\n')\n",
    "                df.iat[row_counter,column_counter] = cell_text + ''.join(stars).strip('\\n')\n",
    "                column_counter += 1\n",
    "        row_counter += 1\n",
    "    \n",
    "    # fill in the city_name\n",
    "    df['city_name'] = city_name.replace('_', ' ')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframes from wiki tables\n",
    "dfs = []\n",
    "for city_name in city_urls:\n",
    "    with open(os.path.join(fp, city_name + '_page_content.html')) as html:\n",
    "        soup = bs4.BeautifulSoup(html)\n",
    "        table = soup.find_all(name='table')\n",
    "        if city_name == 'san_francisco': # sf has two separate tables that need to be merged\n",
    "            sf1 = wiki_table_to_df(table[0], city_name)\n",
    "            sf2 = wiki_table_to_df(table[1], city_name)\n",
    "            sf_merged = pd.merge(sf2, sf1, how='outer', on=['city_name', 'Name'])\n",
    "            sf_merged.insert(2, 'Neighborhood/City', sf_merged['Neighborhood/City_x'].combine_first(sf_merged['Neighborhood/City_y']))\n",
    "            sf_merged.drop(['Neighborhood/City_x', 'Neighborhood/City_y'], axis=1, inplace=True)\n",
    "            dfs.append(sf_merged)\n",
    "        else:\n",
    "            dfs.append(wiki_table_to_df(table[0], city_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean values of closed restaurants, once a restaurant closes, assume it remains closed\n",
    "def impute_closed(df):\n",
    "    '''\n",
    "    Takes a dataframe with restaurant star ratings by year and imputes:\n",
    "        (1) 'Closed' for years after a restaurant has been marked as Closed\n",
    "        (2) NaN for cells that are empty strings\n",
    "    '''\n",
    "    closed_regex = re.compile(r'(?i)closed')\n",
    "    row_counter = 0\n",
    "    for row in range(0, df.shape[0]):\n",
    "        column_counter = 0\n",
    "        for column in range(0, df.shape[1]):\n",
    "            cell_text = str(df.iat[row_counter, column_counter])\n",
    "            left_cell_text = str(df.iat[row_counter, max(column_counter-1, 0)])\n",
    "            # if cell contains closed then change cell value to 'Closed'\n",
    "            if closed_regex.search(cell_text) is not None:\n",
    "                df.iat[row_counter, column_counter] = 'Closed'\n",
    "            elif left_cell_text == 'Closed':\n",
    "                df.iat[row_counter, column_counter] = 'Closed'\n",
    "            # change cells with empty strings to nan\n",
    "            elif not(cell_text):\n",
    "                df.iat[row_counter, column_counter] = np.nan\n",
    "            column_counter += 1\n",
    "        row_counter +=1    \n",
    "    return df\n",
    "    \n",
    "for i in range(0, len(dfs)):\n",
    "    dfs[i] = impute_closed(dfs[i])\n",
    "    dfs[i].replace([np.nan, '1 star', '2 stars', '3 stars'], [0, 1, 2, 3], inplace=True)\n",
    "    dfs[i].drop(dfs[i].columns[2], axis=1, inplace=True)\n",
    "    dfs[i] = dfs[i].melt(id_vars=['city_name', 'Name'], var_name='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def union_dfs(df_list):\n",
    "    '''\n",
    "    Takes a list of dataframes and returns the union of the dataframes\n",
    "    '''\n",
    "    final_df = pd.DataFrame()\n",
    "    for df in df_list:\n",
    "        final_df = final_df.append(df)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# union city dataframes, sort values, rename columns\n",
    "star_df = union_dfs(df_list=dfs).sort_values(['city_name', 'Name', 'year']).reset_index(drop=True)\n",
    "star_df.columns = ['city_name', 'rest_name', 'year', 'stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique city and restaurant name combinations for web scraping\n",
    "rest_df = star_df[['city_name', 'rest_name']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save interim data to disk\n",
    "export_folder = os.path.join('.', 'data', '2_wiki-interim')\n",
    "if not os.path.isdir(export_folder):\n",
    "    os.mkdir(export_folder)\n",
    "\n",
    "star_df.to_csv(os.path.join(export_folder, 'stars.csv'), index=False)\n",
    "rest_df.to_csv(os.path.join(export_folder, 'restaurants.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('base': conda)",
   "language": "python",
   "name": "python37164bitbasecondad46c76a097634dd1a9ae07bdfee2f8cb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
